---
title: "XDB: A Task-Centric AI-Native DBMS for Model Management and Inference."
collection: publications
permalink: /publication/2025-09-06-EmmaGNN
excerpt: 'This paper is about an AI-native DBMS for model management and inference.'
date: 2025-09-06
venue: 'SIGMOD'
# paperurl: 'https://XXX'
citation: 'Sai Wu, Ruichen Xia, Dingyu Yang, Rui Wang, Huihang Lai, Jiarui Guan, Jiameng Bai, Dongxiang Zhang, Xiu Tang, Zhongle Xie, Peng Lu, Gang Chen. "XDB: A Task-Centric AI-Native DBMS for Model Management and Inference."  The ACM Special Interest Group on Management of Data (SIGMOD 2026) 2026'
---

The increasing demand for deep neural inference within database environments has driven the emergence of AI‑native DBMSs. However, existing solutions either rely on model-centric designs requiring developers to manually select, configure, and maintain models, resulting in high development overhead, or adopt task-centric AutoML approaches with high computational costs and poor DBMS integration. We present XDB, a task‑centric AI‑native DBMS that automates model storage, selection, and inference within PostgreSQL. To enable flexible, I/O‑efficient storage of deep learning models, we first introduce specialized schemas and multi-dimensional tensor data types to support BLOB‑based all‑in‑one and decoupled model storage. Then we design a transfer learning framework for model selection in two phases, which builds a transferability subspace via offline embedding of historical tasks and employs online projection through feature-aware mapping for real‑time tasks. To further optimize inference throughput, we propose pre‑embedding with vectoring sharing to eliminate redundant computations and DAG‑based batch pipelines with cost‑aware scheduling to minimize the inference time. Implemented as a PostgreSQL extension with LibTorch, XDB outperforms AI‑native DBMSs (EvaDB, Madlib, GaussML) and AutoML platforms (AutoGluon, AutoKeras, AutoSklearn) across nine public datasets, encompassing series, NLP, and image tasks. Our evaluation demonstrates a robust balance among accuracy, resource consumption, and time cost in model selection and significant gains in throughput and resource efficiency.
